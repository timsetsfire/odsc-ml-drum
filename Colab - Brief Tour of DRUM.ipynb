{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Brief Tour of DRUM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsetsfire/odsc-ml-drum/blob/main/Colab%20-%20Brief%20Tour%20of%20DRUM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IzhGAhUajyp"
      },
      "source": [
        "# DRUM\n",
        "\n",
        "About [DRUM](https://github.com/datarobot/datarobot-user-models/tree/master/custom_model_runner)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqlULeRiamIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1abb4c-dde2-4218-99e8-82ec4d0390a5"
      },
      "source": [
        "!pip install datarobot-drum -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.7MB 3.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 48.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 44.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 6.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 44.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 788kB 45.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 41.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 42.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808kB 40.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 552kB 39.8MB/s \n",
            "\u001b[?25h  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD0EgjpQatZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6283bf-f02c-472c-baee-796841d2a1be"
      },
      "source": [
        "!git clone https://github.com/timsetsfire/odsc-ml-drum.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'odsc-ml-drum'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 537 (delta 39), reused 0 (delta 0), pack-reused 459\u001b[K\n",
            "Receiving objects: 100% (537/537), 83.03 MiB | 36.71 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyqxh3D1ajyt"
      },
      "source": [
        "## Help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjW2OHdXajyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63e4767-d3d3-464c-ebd9-645a55daf3be"
      },
      "source": [
        "!drum --help"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum [-h] [--version]\n",
            "            {score,fit,perf-test,validation,server,new,push} ...\n",
            "\n",
            "Run user model\n",
            "\n",
            "positional arguments:\n",
            "  {score,fit,perf-test,validation,server,new,push}\n",
            "                        Commands\n",
            "    score               Run predictions in batch mode\n",
            "    fit                 Fit your model to your data\n",
            "    perf-test           Run performance tests\n",
            "    validation          Run validation checks against the model\n",
            "    server              serve the model via REST APIs\n",
            "    new                 Create new model/env template\n",
            "    push                Add your modeling code into DataRobot\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --version             show program's version number and exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7vTBHZajyy"
      },
      "source": [
        "## New"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJr3bi9_ajyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cbc34e-f3e4-4517-d564-ef3aa4042f61"
      },
      "source": [
        "!drum new -h"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum new [-h] [--verbose]\n",
            "                [--logging-level {noset,debug,info,warn,warning,error,critical}]\n",
            "                {model} ...\n",
            "\n",
            "Create new model/env template\n",
            "\n",
            "positional arguments:\n",
            "  {model}               Commands\n",
            "    model               Create a new modeling code directory template\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --verbose             Show verbose output\n",
            "  --logging-level {noset,debug,info,warn,warning,error,critical}\n",
            "                        Logging level to use\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQkkJ2bzajy2"
      },
      "source": [
        "Create a new template where you will place model artifacts.  This will generate a custom.py file to aid in adding hooks for you model if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wS9hpIajy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10132998-3355-4e1f-ba1d-ff04894cbf81"
      },
      "source": [
        "!drum new model --code-dir odsc-ml-drum/src/other_models/drum-fit-model  --language python --verbose --logging-level debug"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected template generation mode\n",
            "2020-12-02 00:46:18,542 DEBUG drum.CMTemplateGenerator:  templates_dir: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates\n",
            "2020-12-02 00:46:18,543 DEBUG drum.CMTemplateGenerator:  lang: RunLanguage.PYTHON\n",
            "2020-12-02 00:46:18,543 DEBUG drum.CMTemplateGenerator:  Templates are at: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates\n",
            "2020-12-02 00:46:18,543 DEBUG drum.CMTemplateGenerator:  vars: {'custom_name': 'custom.py',\n",
            " 'gen_command': 'drum new model --language python',\n",
            " 'gen_date': 'Wed Dec  2 00:46:18 2020'}\n",
            "2020-12-02 00:46:18,549 DEBUG drum.CMTemplateGenerator:  src: /usr/local/lib/python3.6/dist-packages/datarobot_drum/drum/../resource/templates/custom_python_template.py.j2 dst:/content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py\n",
            "2020-12-02 00:46:18,549 DEBUG drum.CMTemplateGenerator:  vars: {'custom_name': 'custom.py',\n",
            " 'gen_command': 'drum new model --language python',\n",
            " 'gen_date': 'Wed Dec  2 00:46:18 2020'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEitzYTXajy5"
      },
      "source": [
        "## Fit\n",
        "\n",
        "Fit mode\n",
        "\n",
        "Note: Running fit inside of DataRobot is currently in alpha. Check back soon for the opportunity to test out this functionality yourself.\n",
        "\n",
        "drum can run your training model to make sure it can produce a trained model artifact before adding the training model into DataRobot.\n",
        "\n",
        "Note: If you don't provide class label, DataRobot tries to autodetect the labels for you.\n",
        "\n",
        "You can also use drum on regression datasets, and soon you will also be able to provide row weights. Checkout the drum fit --help output for further details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LvOGsTdajy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff32f01d-7931-4eeb-d13b-003b089021fa"
      },
      "source": [
        "# install from pip\n",
        "%pip install sagemaker-scikit-learn-extension -q"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 20kB 23.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 2.6MB/s \n",
            "\u001b[?25h  Building wheel for sagemaker-scikit-learn-extension (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaGdEHjbajy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2193385d-09aa-43d1-8566-6b3dceded0af"
      },
      "source": [
        "!drum fit --code-dir odsc-ml-drum/src/other_models/python3_sklearn_regression --target-type regression --target MEDV --input odsc-ml-drum/data/boston_housing.csv --output odsc-ml-drum/src/other_models/drum-fit-model --verbose"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected fit mode\n",
            "Detected /content/odsc-ml-drum/src/other_models/python3_sklearn_regression/custom.py .. trying to load hooks\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: python_fit\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.1 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "Maximum memory usage: 171MB\n",
            "Files were overwritten: {'/content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py', '/content/odsc-ml-drum/src/other_models/drum-fit-model/README.md'}\n",
            "Detected /content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py .. trying to load hooks\n",
            "2020-12-02 00:46:27.706880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: generic_predictor\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "Success ðŸŽ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9MBcfLIajzA"
      },
      "source": [
        "## Perf-tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAli-2gdcCGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59184bf1-e997-4aba-8af6-da1a6cd139da"
      },
      "source": [
        "!drum perf-test --help"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: drum perf-test [-h] -cd CODE_DIR [--verbose] --input INPUT\n",
            "                      [--positive-class-label POSITIVE_CLASS_LABEL]\n",
            "                      [--negative-class-label NEGATIVE_CLASS_LABEL]\n",
            "                      [--class-labels CLASS_LABELS [CLASS_LABELS ...]]\n",
            "                      [--class-labels-file CLASS_LABELS_FILE]\n",
            "                      [--docker DOCKER] [--memory MEMORY] [-s SAMPLES]\n",
            "                      [-i ITERATIONS] [--timeout TIMEOUT] [--in-server]\n",
            "                      [--url URL] [--production] [--max-workers MAX_WORKERS]\n",
            "                      [--language {python,r,java}] [--show-stacktrace]\n",
            "                      [--target-type {binary,multiclass,regression,anomaly,unstructured,transform}]\n",
            "                      [--query QUERY] [--content-type CONTENT_TYPE]\n",
            "\n",
            "        Test the performance of an inference model. This is done by internally using the server\n",
            "        sub command to serve the model. Then sending multiple requests to the server and \n",
            "        measuring the time it takes to complete each request. \n",
            "        \n",
            "        The test is mixing several requests sizes. The idea is to get a coverage of several\n",
            "        sizes, from the smallest request containing only 1 row of data, up to the largest \n",
            "        request containing up to 50MB of data.\n",
            "        \n",
            "        At the end of the test, a summary of the test will be displayed. For each request size,\n",
            "        the following fields will be shown:\n",
            "        \n",
            "         size: size of the requests in bytes or Megabytes.\n",
            "         samples: number of samples this request size contained.\n",
            "         iters: number of times this request size was sent\n",
            "         min: minimum time measured for this request size (in seconds)\n",
            "         avg: average time of the this request size (in seconds)\n",
            "         max: maximum time measured for this request size (in seconds)\n",
            "         used: amount of memory used by drum at the end of this request size (MB)\n",
            "         container limit: if tests run in docker container, memory limit for it (MB)\n",
            "         total physical: total amount of physical memory avail on the current machine (MB)\n",
            "        \n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -cd CODE_DIR, --code-dir CODE_DIR\n",
            "                        Custom model code dir\n",
            "  --verbose             Show verbose output\n",
            "  --input INPUT         Path to an input dataset\n",
            "  --positive-class-label POSITIVE_CLASS_LABEL\n",
            "                        Positive class label for a binary classification case.\n",
            "  --negative-class-label NEGATIVE_CLASS_LABEL\n",
            "                        Negative class label for a binary classification case.\n",
            "  --class-labels CLASS_LABELS [CLASS_LABELS ...]\n",
            "                        The class labels for a multiclass classification case.\n",
            "                        Labels should be in the order as the predicted\n",
            "                        probabilities produced by the model.\n",
            "  --class-labels-file CLASS_LABELS_FILE\n",
            "                        A file containing newline separated class labels for a\n",
            "                        multiclass classification case. Labels should be in\n",
            "                        the order as the predicted probabilities produced by\n",
            "                        the model.\n",
            "  --docker DOCKER       Docker image to use to run drum in the perf-test mode,\n",
            "                        or a directory, containing a Dockerfile, which can be\n",
            "                        built into a docker image.\n",
            "  --memory MEMORY       Amount of memory to allow the docker container to\n",
            "                        consume. The value will be passed to the docker run\n",
            "                        command to both the --memory and --memory-swap\n",
            "                        parameters. b,k,m,g suffixes are supported\n",
            "  -s SAMPLES, --samples SAMPLES\n",
            "                        Number of samples\n",
            "  -i ITERATIONS, --iterations ITERATIONS\n",
            "                        Number of iterations\n",
            "  --timeout TIMEOUT     Test case timeout\n",
            "  --in-server           Show performance inside server\n",
            "  --url URL             Run performance against the given prediction server\n",
            "  --production          Run prediction server in production mode uwsgi + nginx\n",
            "  --max-workers MAX_WORKERS\n",
            "                        Max number of uwsgi workers in server production mode\n",
            "  --language {python,r,java}\n",
            "                        Language to use for the new model/env template to\n",
            "                        create\n",
            "  --show-stacktrace     Show stacktrace when error happens.\n",
            "  --target-type {binary,multiclass,regression,anomaly,unstructured,transform}\n",
            "                        Target type\n",
            "  --query QUERY         Additional query params unstructured mode. (Simulates\n",
            "                        http request query params.)\n",
            "  --content-type CONTENT_TYPE\n",
            "                        Additional content type for unstructured mode.\n",
            "                        (Simulates http request Content-Type header, default:\n",
            "                        'text/plain; charset=utf8')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx_CRwntajzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb091b6-6ee7-4ed7-e076-a03390abdf9b"
      },
      "source": [
        "!drum perf-test -cd odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing_inference.csv --target-type regression --show-stacktrace"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DRUM performance test\n",
            "Model:      /content/odsc-ml-drum/src/other_models/drum-fit-model\n",
            "Data:       /content/odsc-ml-drum/data/boston_housing_inference.csv\n",
            "# Features: 13\n",
            "Preparing test data...\n",
            "\n",
            "\n",
            "\n",
            "Running test case with timeout: 180\n",
            "Running test case: 72 bytes - 1 samples, 100 iterations\n",
            "\u001b[KProcessing |################################| 100/100\n",
            "Running test case with timeout: 180\n",
            "Running test case: 0.1MB - 1449 samples, 50 iterations\n",
            "\u001b[KProcessing |################################| 50/50\n",
            "Running test case with timeout: 180\n",
            "Running test case: 10MB - 144964 samples, 5 iterations\n",
            "\u001b[KProcessing |################################| 5/5\n",
            "Running test case with timeout: 180\n",
            "Running test case: 50MB - 724823 samples, 1 iterations\n",
            "\u001b[KProcessing |################################| 1/1\n",
            "Test is done stopping drum server\n",
            "\u001b[m\u001b[?7h\u001b[4l\u001b>\u001b7\u001b[r\u001b[?1;3;4;6l\u001b8\n",
            "  size     samples   iters    min     avg     max    used (MB)   total physical \n",
            "                                                                      (MB)      \n",
            "================================================================================\n",
            "72 bytes         1     100   0.011   0.013   0.020     507.547         13021.090\n",
            "0.1MB         1449      50   0.025   0.030   0.040     512.469         13021.090\n",
            "10MB        144964       5   0.714   0.727   0.743     590.852         13021.090\n",
            "50MB        724823       1   3.348   3.348   3.348     854.703         13021.090\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwLCB4xbajzE"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tPyIIy4TajzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b22dfa5-aef0-41ab-d6ca-42378606cf24"
      },
      "source": [
        "!drum validation --code-dir odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing.csv --target-type regression > drum_validation.log\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-02 00:48:23.556621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:27.618687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:31.648752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:35.681181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:39.699400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:43.712573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:47.754418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:51.783702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:48:55.949838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:49:00.112403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:49:04.126407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:49:08.147698: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:49:12.170720: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n",
            "2020-12-02 00:49:16.174919: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
            "  FutureWarning)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Zoc00-ajzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e649c065-fae4-4f2c-c820-6e620cddf537"
      },
      "source": [
        "!tail -20 drum_validation.log"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Predictions\n",
            "0      30.522568\n",
            "1      24.560272\n",
            "2      30.692869\n",
            "3      29.985301\n",
            "4      29.225193\n",
            "..           ...\n",
            "501    24.361584\n",
            "502    22.930635\n",
            "503    28.721774\n",
            "504    27.304425\n",
            "505    23.196687\n",
            "\n",
            "[506 rows x 1 columns]\n",
            "\n",
            "\n",
            "Validation checks results\n",
            "      Test case         Status\n",
            "==============================\n",
            "Null value imputation   PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPp4Fw4gajzK"
      },
      "source": [
        "## Score\n",
        "\n",
        "Score the data in batch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeLQDoQsajzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7039034-af13-460f-d4ef-69f06f8c41b6"
      },
      "source": [
        "!drum score --code-dir odsc-ml-drum/src/other_models/drum-fit-model --input odsc-ml-drum/data/boston_housing_inference.csv --target-type regression --verbose\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected score mode\n",
            "Detected /content/odsc-ml-drum/src/other_models/drum-fit-model/custom.py .. trying to load hooks\n",
            "2020-12-02 00:49:20.651086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32mComponent: generic_predictor\u001b[0m\n",
            "\u001b[32mLanguage:  Python\u001b[0m\n",
            "\u001b[32mOutput:\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32m------------------------------------------------------------\u001b[0m\n",
            "\u001b[32mRuntime:    0.0 sec\u001b[0m\n",
            "\u001b[32mNR outputs: 0\u001b[0m\n",
            "\u001b[32m============================================================\u001b[0m\n",
            "\u001b[32m \u001b[0m\n",
            "   Predictions\n",
            "0    30.522568\n",
            "1    24.560272\n",
            "2    30.692869\n",
            "3    29.985301\n",
            "4    29.225193\n",
            "5    26.322876\n",
            "6    22.370245\n",
            "7    18.959008\n",
            "8    10.061568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4FECnaYajzN"
      },
      "source": [
        "## Server\n",
        "\n",
        "This will be covered in main notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JlMmBXrcmHr"
      },
      "source": [
        "import subprocess"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2pMKCIPajzN"
      },
      "source": [
        "inference_server = subprocess.Popen([\"drum\",  \n",
        "                                     \"server\", \n",
        "                                     \"--code-dir\", \"odsc-ml-drum/src/other_models/drum-fit-model\", \n",
        "                                     \"--target-type\", \"regression\",\n",
        "                                     \"--address\", \"localhost:1234\"]) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9WBSsfBc4E6"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO, BytesIO\n",
        "import os\n",
        "import time\n",
        "# -----------------------------------------------------------\n",
        "# Forms\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "## endpoint for model\n",
        "drum_url = \"http://localhost\"\n",
        "drum_port = \"1234\"\n",
        "def score(data, url = \"http://localhost\", port = \"1234\"):\n",
        "    b_buf = BytesIO()\n",
        "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
        "    b_buf.seek(0) \n",
        "    url = \"{}:{}/predict/\".format(url, port)\n",
        "    files = [\n",
        "        ('X', b_buf)\n",
        "    ]\n",
        "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
        "    return response"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-sbO0DsdZj5"
      },
      "source": [
        "df = pd.read_csv(\"odsc-ml-drum/data/boston_housing_inference.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgMaGMPpdd9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d9b642-5ac8-4a08-d589-b609c26a4421"
      },
      "source": [
        "score(df,drum_url, drum_port).json()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predictions': [30.5225680706,\n",
              "  24.5602720246,\n",
              "  30.6928692906,\n",
              "  29.9853006924,\n",
              "  29.2251933589,\n",
              "  26.3228764654,\n",
              "  22.3702449939,\n",
              "  18.9590083659,\n",
              "  10.0615675685]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjo46oCPajzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1aaf59-ec2c-4cb5-c61e-573ba3767a35"
      },
      "source": [
        "requests.post(\"{}:{}/shutdown/\".format(drum_url, drum_port))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkakaEHedqxX"
      },
      "source": [
        "inference_server.terminate()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAdDUlgtd4pw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}