{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DRUM - Automated Model Serving Made Easy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsetsfire/odsc-ml-drum/blob/main/Colab%20-%20DRUM%20Model%20Serving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxOyJ2xMrlL"
      },
      "source": [
        "# DRUM - Automated Model Serving Made Easy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OUbruxUMrlM"
      },
      "source": [
        " We'll get our hands dirty by \n",
        "\n",
        "* Building a simple regression model using Scikit\n",
        "* Using DRUM for Batch Scoring\n",
        "* Using DRUM to get a REST API endpoint\n",
        "* Show a simple example app connected to the REST API\n",
        "* H2O, Keras, XGBoost, and DataRobot\n",
        "* Add a DataRobot remote agent if you are interested in further model monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykjnP6-ZMrlM"
      },
      "source": [
        "# Build a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IDgpv8NMs7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de2b8ed-650e-457d-8025-52ffc72c9db8"
      },
      "source": [
        "!git clone https://github.com/timsetsfire/odsc-ml-drum.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'odsc-ml-drum'...\n",
            "remote: Enumerating objects: 598, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 598 (delta 75), reused 0 (delta 0), pack-reused 459\u001b[K\n",
            "Receiving objects: 100% (598/598), 83.45 MiB | 33.30 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x86AAdVeMjl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958705c5-3797-43c2-b454-1372c6c99002"
      },
      "source": [
        "!pip install -r /content/odsc-ml-drum/colab-requirements.txt -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 276kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7MB 24.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 148.9MB 83kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 788kB 45.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 53.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 808kB 38.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 41.2MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HyGq4hkcMLG",
        "outputId": "66932ce5-c47d-4d75-b491-083eea00aa8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%sh\n",
        "pip install datarobot-drum -U -q"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbr2w4si9RVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d8ff1e-950b-4db4-ac31-3b1c0daf266f"
      },
      "source": [
        "!sudo apt install nginx -q"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "nginx is already the newest version (1.14.0-0ubuntu1.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAkNyQLWMrlN"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "## load data\n",
        "\n",
        "df = pd.read_csv('/content/odsc-ml-drum/data/boston_housing.csv')\n",
        "df.head()\n",
        "\n",
        "## set features and target\n",
        "\n",
        "X = df.drop('MEDV', axis=1)\n",
        "y = df['MEDV']\n",
        "\n",
        "## train the model\n",
        "rf = RandomForestRegressor(n_estimators = 20)\n",
        "rf.fit(X,y)\n",
        "\n",
        "## serialize the model\n",
        "\n",
        "with open('/content/odsc-ml-drum/src/custom_model/rf.pkl', 'wb') as pkl:\n",
        "    pickle.dump(rf, pkl)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg-IGqO2bEI9"
      },
      "source": [
        "# Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FVQGClrbDz4",
        "outputId": "2d83b103-a65f-4ee2-b033-03570780f771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%sh \n",
        "drum perf-test --code-dir /content/odsc-ml-drum/src/custom_model \\\n",
        "--input /content/odsc-ml-drum/data/boston_housing_inference.csv \\\n",
        "--target-type regression"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DRUM performance test\n",
            "Model:      /content/odsc-ml-drum/src/custom_model\n",
            "Data:       /content/odsc-ml-drum/data/boston_housing_inference.csv\n",
            "# Features: 13\n",
            "Preparing test data...\n",
            "\n",
            "\n",
            "\n",
            "Running test case with timeout: 600\n",
            "Running test case: 72 bytes - 1 samples, 100 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 0.1MB - 1449 samples, 50 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 10MB - 144964 samples, 5 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 50MB - 724823 samples, 1 iterations\n",
            "Test is done stopping drum server\n",
            "\n",
            "  size     samples   iters    min     avg     max    used (MB)   total physical \n",
            "                                                                      (MB)      \n",
            "================================================================================\n",
            "72 bytes         1     100   0.007   0.008   0.011     554.668         12993.484\n",
            "0.1MB         1449      50   0.014   0.018   0.122     560.395         12993.484\n",
            "10MB        144964       5   0.604   0.614   0.637     648.484         12993.484\n",
            "50MB        724823       1   3.062   3.062   3.062     868.867         12993.484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tput: terminal attributes: No such device or address\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vr0Z05lbHEH"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjjQvz57bHb_",
        "outputId": "897d32b6-020a-4a13-9efd-03b41ecd50c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%sh \n",
        "drum validation --code-dir /content/odsc-ml-drum/src/custom_model \\\n",
        "--input /content/odsc-ml-drum/data/boston_housing_inference.csv \\\n",
        "--target-type regression > drum_validation.log"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-27 01:34:33.385143: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:36.870478: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:40.348295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:43.839968: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:47.334422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:50.853418: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:54.368986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:34:57.874320: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:01.412478: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:04.889269: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:08.394590: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:11.868318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:15.310537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:35:18.677363: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcHLtmE0bRdK",
        "outputId": "5f3fcc8d-25a9-4a21-dfed-0fced723c0a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%sh\n",
        "tail drum_validation.log"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Validation checks results\n",
            "      Test case          Status   Details\n",
            "=========================================\n",
            "Basic batch prediction   PASSED          \n",
            "Null value imputation    PASSED          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4p0zDG-VWJP"
      },
      "source": [
        "# Batch Scoring with DRUM\n",
        "<a id=\"setup_complete\"></a>\n",
        "\n",
        "At this point our model has been written to disk and we want to start making predictions with it.  To do this, we'll leverage DRUM and it's ability to natively handle our scikit learn model, all we need to do is tell DRUM where it resides as well as the data we wish to score.  \n",
        "\n",
        "There are a lot of frameworks which DRUM supports nateively, but for those which DRUM doesn't support of these shelf, we'll just need to create some custom hooks so DRUM.  In this example, we'll highlight some very simple custom hooks, and will provide links to more complex examples.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_OOeqEx6hqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d23a7aa-2b81-4413-a45f-e69a6fbebb4b"
      },
      "source": [
        "%%sh \n",
        "drum score --code-dir /content/odsc-ml-drum/src/custom_model \\\n",
        "--input /content/odsc-ml-drum/data/boston_housing_inference.csv \\\n",
        "--output /content/odsc-ml-drum/data/predictions.csv --target-type regression"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-27 01:21:56.349475: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLQnWJw_MrlU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8b20d160-6b25-436b-feb1-4b2c6132983d"
      },
      "source": [
        "pd.read_csv(\"/content/odsc-ml-drum/data/predictions.csv\").head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predictions\n",
              "0       26.500\n",
              "1       21.880\n",
              "2       35.015\n",
              "3       34.910\n",
              "4       35.690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmS971iweH6t"
      },
      "source": [
        "# Start the inference server locally\n",
        "\n",
        "Batch scoring can be very useful, but the utility DRUM offers does not stop there.  We can also leverage DRUM to serve our model as a RESTful API endpoint.  The only thing that changes is the way we will structure the command - using the `server` mode instead of `score` model.  We'll also need to provide an address which is NOT in use.  \n",
        "\n",
        "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7BrHC1gYjHD"
      },
      "source": [
        "import subprocess\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import yaml\n",
        "import time\n",
        "import os\n",
        "import datarobot as dr\n",
        "from pprint import pprint"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crlRTOHcMrld"
      },
      "source": [
        "run_inference_server = [\"drum\",\n",
        "              \"server\",\n",
        "              \"--code-dir\",\"/content/odsc-ml-drum/src/custom_model\", \n",
        "              \"--address\", \"0.0.0.0:6789\", \n",
        "              \"--show-perf\",\n",
        "              \"--target-type\", \"regression\",\n",
        "              \"--logging-level\", \"info\",\n",
        "              \"--show-stacktrace\",\n",
        "              \"--verbose\",\n",
        "              \"--production\", \n",
        "              \"--max-workers\", \"5\"\n",
        "              ]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWvksr_sYlEr"
      },
      "source": [
        "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZfzEEPZ9kZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11847486-9a34-493f-df73-24df3cdfb947"
      },
      "source": [
        "!sudo service nginx status"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * nginx is not running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFenY-leJo3"
      },
      "source": [
        "## Ping the Server to make sure it is running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmh7SRfQVnTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525de01f-d1f7-4abc-c22e-11965c5082e0"
      },
      "source": [
        "## confirm the server is running\n",
        "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
        "print('check status')\n",
        "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'{\"message\": \"OK\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsaTgXOeNMG"
      },
      "source": [
        "## Send data to server for inference\n",
        "\n",
        "The request must provide our dataset as form data.  In order to do so, we'll create a simple python function to pass the data over appropriately.  We'll leverage the same function in our simple flask app a little later.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ-sZcHMYmRx"
      },
      "source": [
        "def score(data, port = \"6789\"):\n",
        "    b_buf = BytesIO()\n",
        "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
        "    b_buf.seek(0)\n",
        "  \n",
        "    url = \"http://localhost:{}/predict/\".format(port)\n",
        "    files = [\n",
        "        ('X', b_buf)\n",
        "    ]\n",
        "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
        "    return response"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjdKXUcUWUXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd128ff-33f1-402a-d185-bcaba4c12a30"
      },
      "source": [
        "# %%timeit\n",
        "scoring_data = pd.read_csv(\"/content/odsc-ml-drum/data/boston_housing_inference.csv\")\n",
        "predictions = score(scoring_data).json() ## score entire dataset but only show first 5 records\n",
        "pprint(predictions)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'predictions': [26.5,\n",
            "                 21.88,\n",
            "                 35.015,\n",
            "                 34.91,\n",
            "                 35.69,\n",
            "                 27.19,\n",
            "                 21.56,\n",
            "                 23.47,\n",
            "                 16.455]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a20HW9uMrl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92186acb-5dd1-45e2-8b88-81fceeb62881"
      },
      "source": [
        "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'{\"message\": \"OK\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG3HHHnR942W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a2fd0a-04ec-4885-c722-54f1df563e53"
      },
      "source": [
        "inference_server.terminate()\n",
        "inference_server.stdout.readlines()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Name: uWSGI\\n',\n",
              " b'Version: 2.0.19.1\\n',\n",
              " b'Summary: The uWSGI server\\n',\n",
              " b'Home-page: https://uwsgi-docs.readthedocs.io/en/latest/\\n',\n",
              " b'Author: Unbit\\n',\n",
              " b'Author-email: info@unbit.it\\n',\n",
              " b'License: GPLv2+\\n',\n",
              " b'Location: /usr/local/lib/python3.7/dist-packages\\n',\n",
              " b'Requires: \\n',\n",
              " b'Required-by: mlpiper\\n',\n",
              " b'Detected REST server mode - this is an advanced option\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
              " b'\\x1b[32mComponent: uwsgi_serving\\x1b[0m\\n',\n",
              " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
              " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
              " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXsO0ZQ9wGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd36321c-5e53-4e30-f575-314671b597b9"
      },
      "source": [
        "%%sh\n",
        "nginx -s stop\n",
        "sudo service nginx status"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * nginx is not running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM8z8v8cTaqD"
      },
      "source": [
        "# requests.request(\"POST\", \"http://0.0.0.0:6789/shutdown/\").content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIGQMPjgMrl3"
      },
      "source": [
        "# Value Prop\n",
        "\n",
        "One may ask, what is the benefit to be had here?  Well, first of, there is not need for me to write an api to get the model up and running.  Second, DRUM allows me to abstract the framework away (provided I'm using one that is natively supported, or I can write enough python so that DRUM understands how to hook up to the model.  \n",
        "\n",
        "For example, I could hot swap models as I see fit (see exampels in `./src/other_models`)\n",
        "\n",
        "While we will run through several other frameworks with in `score` you can bet they are supported in `server` mode as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGKKPfNMrl4"
      },
      "source": [
        "#### H2O Mojo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPxTpC-NMrl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f17d85c-4162-477f-c3e5-764899f5b71f"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/h2o_mojo/regression --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
            "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
            "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
            "   Predictions\n",
            "0    24.504000\n",
            "1    22.492000\n",
            "2    34.554001\n",
            "3    34.420001\n",
            "4    35.289001\n",
            "5    28.394001\n",
            "6    21.936000\n",
            "7    23.451000\n",
            "8    17.065000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35pX5I94Mrl7"
      },
      "source": [
        "#### Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6CNMITMrl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0414a90a-3715-4f6e-e707-4e007745db69"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/python3_keras_joblib --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-27 01:22:42.837377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "2021-05-27 01:22:44.372695: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-27 01:22:44.433723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.434365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-05-27 01:22:44.434414: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-27 01:22:44.553453: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-27 01:22:44.553592: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-27 01:22:44.656989: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-27 01:22:44.668393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-27 01:22:44.966345: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-05-27 01:22:44.975261: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-27 01:22:44.975677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-27 01:22:44.975831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.976556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.979442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-05-27 01:22:44.979871: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-05-27 01:22:44.980121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.980720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-05-27 01:22:44.980809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.981419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:44.981977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-05-27 01:22:44.984862: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-27 01:22:49.236902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-27 01:22:49.236956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-05-27 01:22:49.236977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-05-27 01:22:49.237242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:49.237953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:49.238586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-27 01:22:49.239139: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-05-27 01:22:49.239188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-05-27 01:22:49,363 WARNING tensorflow:  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "2021-05-27 01:22:49.522783: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-05-27 01:22:49.525790: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000179999 Hz\n",
            "2021-05-27 01:22:49.706477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-27 01:22:52.244030: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "   Predictions\n",
            "0    23.668932\n",
            "1    23.421118\n",
            "2    31.283525\n",
            "3    33.996525\n",
            "4    33.757940\n",
            "5    28.036715\n",
            "6    20.675852\n",
            "7    19.578413\n",
            "8    19.676756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsanmxC-Mrl9"
      },
      "source": [
        "#### XGBoost\n",
        "\n",
        "Requires XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myCq6e63Mrl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c6959e-2577-498b-a1a9-e82b204c84ae"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/python3_xgboost --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-05-27 01:22:55.123433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "   Predictions\n",
            "0    24.541843\n",
            "1    21.260277\n",
            "2    34.018497\n",
            "3    32.569200\n",
            "4    34.248066\n",
            "5    27.282364\n",
            "6    20.803959\n",
            "7    19.645220\n",
            "8    16.968880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuTZhCZMrmA"
      },
      "source": [
        "#### DataRobot Codegen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dTPDvBwMrmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad589b9e-9bcf-4a35-cbc6-8bdfc86f8578"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/dr_codegen --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Predictions\n",
            "0    24.258228\n",
            "1    24.258228\n",
            "2    32.451515\n",
            "3    32.451515\n",
            "4    32.451515\n",
            "5    24.258228\n",
            "6    21.078378\n",
            "7    13.107812\n",
            "8    13.107812\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}